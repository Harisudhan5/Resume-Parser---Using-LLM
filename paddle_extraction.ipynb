{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = './rees.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"IMG\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HARISUDHAN.S ones $\\nspeaktoharisudhan@gmail.com @\\nhari-sudhan-20373a224 (j\\n\\nSTUDENT\\n\\nSUMMARY\\n\\nHighly motivated Data science graduate with strong foundation in Python to work with data related projects and.\\n‘gained some practical experience in internships Passionate about learning skills and working with real - world\\nproblems. Proficient in libraries required for data handling ,preprocessing, analysis and basie concepts of neural\\n‘networks, in deep learning.image processing by undergoing handson - projects to demonstrate my knowledge.\\n\\nEDUCATION PROFESSIONAL EXPERIENCE\\n‘StJoseph's College of Engineering Niograph - Intern\\n\\n‘Asa Data science intern 1 worked on company customer\\n‘elationship-management project which involves scrapping data\\nfrom website storing in database, building machine learning model\\n\\n[Bachelor's Degree in Artificial Intelligence\\nand Data Science .CGPA- 89)\\n\\n2a ~ 2025 to predict the target customers and vizualizing dashboards to\\n\\nARLM Matric Hr-SecSchool Understand the insights rom the dt,\\n\\nsea ssic Code Clause - Project Intern\\n\\n2020 - 2022 ‘Asa projet inter came trough various machine earning\\nSlgorthne and asigued to work on speci set of project to\\n\\nSKILLS atalyze the data and construct models forthe use - ease. Fist\\n\\nproject was to analyze the light dataset and to predict the flight\\n‘delay time and the second project was to create a model which\\ntakes image as input and gives gender and age as output.\\n\\n‘The Sparks Foundation -Data Science Intern\\n\\nBeing Data Science inter J worked with Machine Learning Projects\\nand Regression problem and solve Regression case problems.\\n‘Teachnook - Python developer\\n\\n‘During my frst internship | gained knowledge of Python andits\\n‘dominance in various domain and came across basics to integrating\\npython with other tools and worked on abject oriented programming\\nProject to setup graphical user interface timer application Later\\nStarted to get proficient in functions discovering lmportantibraries.\\n\\nCERTIFICATIONS\\n\\nPROJECTS\\nPython for verjone {age and Gender dczton Uses human fea np image a\\nHiuacss Pett age andgenderwich wen CNV dense ers\\nIntroduction to Jascrpt nod cpt ofthe Rte mag ie en N28\\n+ Mathematics for Machine Learing {raycale format The network was able to perform beter a\\n‘+ Machine Learning with Pybton ‘determining gender but notin age duet small amount of data for\\n1 Dyn rain Dat since coe\\n+ ask web development «Phishing URLClssification- Detects whether the ul is ether\\n1 CANA RAN architectures ‘St orusfe since mons of dni are eee pr aya\\n5 sQu-Mssat ted fr soc equretoy tango ore rs with\\n1 NLP or Beginners thesccuyof The manu aces to proces the\\nthtaby breaking he rte on conti poe\\nHONORS indewclprtoescte\\n\\n+ Face Emotion detection -Clasifes the emotions of face in\\n\\n* Winer t Haclorword conducted by ating yn etch ce ete the CAN\\n\\naaa Unierayof aryana ‘model The dataset contains 2 raining images with 4<CNN\\n: lakathon First place layers dense layers of 80 epochs with accuracy of 796 accuracy\\n+ Participation of Cybertiavoe + Autism Prediction - Collected dat from diferent sources and\\n\\n{Spoken tutorial Python Exam\\n\\nspoken analyzed the key factors ofthe mental disorder as features to bul\\n\\n‘an ML model that classifies postive or negative with calculation of\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(img)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/01/24 10:19:12] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\koush/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\koush/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\koush\\\\anaconda3\\\\envs\\\\master\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\koush/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/01/24 10:19:15] ppocr DEBUG: dt_boxes num : 98, elapsed : 0.5811352729797363\n",
      "[2024/01/24 10:19:16] ppocr DEBUG: cls num  : 98, elapsed : 1.1636009216308594\n",
      "[2024/01/24 10:19:58] ppocr DEBUG: rec_res num  : 98, elapsed : 42.16063618659973\n"
     ]
    }
   ],
   "source": [
    "result = ocr.ocr(img, cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[[508.0, 11.0], [601.0, 9.0], [601.0, 26.0], [509.0, 28.0]],\n",
       "   ('+91 8438541785', 0.9994903802871704)],\n",
       "  [[[80.0, 21.0], [318.0, 21.0], [318.0, 45.0], [80.0, 45.0]],\n",
       "   ('HARISUDHAN.S', 0.9986152648925781)],\n",
       "  [[[447.0, 35.0], [602.0, 35.0], [602.0, 49.0], [447.0, 49.0]],\n",
       "   ('github.com/Harisudhan5', 0.9984918832778931)],\n",
       "  [[[76.0, 66.0], [149.0, 66.0], [149.0, 83.0], [76.0, 83.0]],\n",
       "   ('STUDENT', 0.9988442659378052)],\n",
       "  [[[415.0, 58.0], [601.0, 58.0], [601.0, 72.0], [415.0, 72.0]],\n",
       "   ('speaktoharisudhan@gmail.com', 0.9905810356140137)],\n",
       "  [[[458.0, 81.0], [601.0, 81.0], [601.0, 94.0], [458.0, 94.0]],\n",
       "   ('hari-sudhan-20373a224', 0.9973166584968567)],\n",
       "  [[[611.0, 84.0], [628.0, 84.0], [628.0, 97.0], [611.0, 97.0]],\n",
       "   ('in', 0.9757499694824219)],\n",
       "  [[[300.0, 149.0], [396.0, 149.0], [396.0, 163.0], [300.0, 163.0]],\n",
       "   ('SUMMARY', 0.9977410435676575)],\n",
       "  [[[66.0, 176.0], [630.0, 176.0], [630.0, 189.0], [66.0, 189.0]],\n",
       "   ('Highly motivated Data science graduate with strong foundation in Python to work with data related projects and',\n",
       "    0.993186354637146)],\n",
       "  [[[69.0, 191.0], [626.0, 191.0], [626.0, 204.0], [69.0, 204.0]],\n",
       "   ('gained some practical experience in internships.Passionate about learning skills and working with real - world',\n",
       "    0.9943690299987793)],\n",
       "  [[[66.0, 205.0], [629.0, 205.0], [629.0, 218.0], [66.0, 218.0]],\n",
       "   ('problems. Proficient in libraries required for data handling ,preprocessing, analysis and basic concepts of neural',\n",
       "    0.9918190240859985)],\n",
       "  [[[70.0, 219.0], [624.0, 219.0], [624.0, 232.0], [70.0, 232.0]],\n",
       "   ('networks, in deep learning,image processing by undergoing handson - projects to demonstrate my knowledge.',\n",
       "    0.9944637417793274)],\n",
       "  [[[65.0, 249.0], [172.0, 249.0], [172.0, 262.0], [65.0, 262.0]],\n",
       "   ('EDUCATION', 0.9982407689094543)],\n",
       "  [[[322.0, 248.0], [575.0, 248.0], [575.0, 261.0], [322.0, 261.0]],\n",
       "   ('PROFESSIONAL EXPERIENCE', 0.9975395202636719)],\n",
       "  [[[63.0, 277.0], [256.0, 278.0], [256.0, 292.0], [63.0, 291.0]],\n",
       "   (\"St.Joseph's College of Engineering\", 0.9998888969421387)],\n",
       "  [[[323.0, 271.0], [425.0, 271.0], [425.0, 284.0], [323.0, 284.0]],\n",
       "   ('Niograph - Intern', 0.968035101890564)],\n",
       "  [[[62.0, 291.0], [252.0, 293.0], [252.0, 306.0], [62.0, 304.0]],\n",
       "   (\"Bachelor's Degree in Artificial Intelligence\", 0.9945153594017029)],\n",
       "  [[[328.0, 287.0], [581.0, 287.0], [581.0, 297.0], [328.0, 297.0]],\n",
       "   ('As a Data science intern I worked on company customer-.',\n",
       "    0.9825038313865662)],\n",
       "  [[[64.0, 307.0], [199.0, 307.0], [199.0, 317.0], [64.0, 317.0]],\n",
       "   ('and Data Science. CGPA - 8.9', 0.9885830879211426)],\n",
       "  [[[328.0, 299.0], [614.0, 299.0], [614.0, 312.0], [328.0, 312.0]],\n",
       "   ('relationship-management project which involves scrapping data',\n",
       "    0.985292911529541)],\n",
       "  [[[64.0, 319.0], [116.0, 319.0], [116.0, 329.0], [64.0, 329.0]],\n",
       "   ('2021 - 2025', 0.9293205142021179)],\n",
       "  [[[328.0, 311.0], [627.0, 311.0], [627.0, 324.0], [328.0, 324.0]],\n",
       "   ('from website, storing in database, building machine learning model',\n",
       "    0.9920490384101868)],\n",
       "  [[[327.0, 324.0], [603.0, 324.0], [603.0, 337.0], [327.0, 337.0]],\n",
       "   ('to predict the target customers and vizualizing dashboards to',\n",
       "    0.9887571930885315)],\n",
       "  [[[63.0, 334.0], [234.0, 335.0], [234.0, 349.0], [63.0, 348.0]],\n",
       "   ('A.R.L.M .Matric .Hr.Sec.School', 0.9975360035896301)],\n",
       "  [[[329.0, 338.0], [501.0, 338.0], [501.0, 348.0], [329.0, 348.0]],\n",
       "   ('understand the insights from the data..', 0.977350115776062)],\n",
       "  [[[63.0, 353.0], [119.0, 353.0], [119.0, 364.0], [63.0, 364.0]],\n",
       "   ('HSE & SSLC', 0.9785320162773132)],\n",
       "  [[[324.0, 354.0], [485.0, 354.0], [485.0, 367.0], [324.0, 367.0]],\n",
       "   ('Code Clause - Project Intern', 0.9939851760864258)],\n",
       "  [[[63.0, 366.0], [119.0, 366.0], [119.0, 377.0], [63.0, 377.0]],\n",
       "   ('2020  2022', 0.9890332221984863)],\n",
       "  [[[323.0, 367.0], [593.0, 368.0], [593.0, 381.0], [323.0, 380.0]],\n",
       "   (' As a project intern I came through various machine learning',\n",
       "    0.989314615726471)],\n",
       "  [[[63.0, 387.0], [126.0, 387.0], [126.0, 404.0], [63.0, 404.0]],\n",
       "   ('SKILLS', 0.9978604912757874)],\n",
       "  [[[323.0, 379.0], [598.0, 380.0], [598.0, 393.0], [323.0, 392.0]],\n",
       "   (' algorithms and assigned to work on specific set of projects to',\n",
       "    0.9951538443565369)],\n",
       "  [[[326.0, 394.0], [604.0, 394.0], [604.0, 404.0], [326.0, 404.0]],\n",
       "   ('analyze the data and construct models for the use - case. First',\n",
       "    0.9933499097824097)],\n",
       "  [[[67.0, 415.0], [114.0, 415.0], [114.0, 426.0], [67.0, 426.0]],\n",
       "   ('Python', 0.9978301525115967)],\n",
       "  [[[326.0, 407.0], [609.0, 407.0], [609.0, 417.0], [326.0, 417.0]],\n",
       "   ('project was to analyze the flight dataset and to predict the flight',\n",
       "    0.9950680136680603)],\n",
       "  [[[66.0, 427.0], [101.0, 427.0], [101.0, 442.0], [66.0, 442.0]],\n",
       "   (' SQL', 0.9207783937454224)],\n",
       "  [[[324.0, 418.0], [605.0, 418.0], [605.0, 431.0], [324.0, 431.0]],\n",
       "   ('delay time and the second project was to create a model which',\n",
       "    0.9887890815734863)],\n",
       "  [[[67.0, 440.0], [186.0, 440.0], [186.0, 453.0], [67.0, 453.0]],\n",
       "   ('Frontend Development', 0.9891296625137329)],\n",
       "  [[[324.0, 432.0], [576.0, 432.0], [576.0, 443.0], [324.0, 443.0]],\n",
       "   ('takes image as input and gives gender and age as output.',\n",
       "    0.9947827458381653)],\n",
       "  [[[68.0, 454.0], [139.0, 454.0], [139.0, 465.0], [68.0, 465.0]],\n",
       "   ('Data Analysis', 0.9787285327911377)],\n",
       "  [[[325.0, 447.0], [575.0, 447.0], [575.0, 460.0], [325.0, 460.0]],\n",
       "   ('The Sparks Foundation -Data Science Intern', 0.9962100982666016)],\n",
       "  [[[67.0, 466.0], [160.0, 466.0], [160.0, 479.0], [67.0, 479.0]],\n",
       "   ('Image Processing', 0.9998421669006348)],\n",
       "  [[[325.0, 460.0], [617.0, 461.0], [617.0, 474.0], [325.0, 473.0]],\n",
       "   (' Being Data Science intern ,I worked with Machine Learning Projects',\n",
       "    0.9862232208251953)],\n",
       "  [[[67.0, 478.0], [158.0, 478.0], [158.0, 491.0], [67.0, 491.0]],\n",
       "   ('Flask Framework', 0.9999265670776367)],\n",
       "  [[[326.0, 474.0], [586.0, 474.0], [586.0, 487.0], [326.0, 487.0]],\n",
       "   ('and Regression problem and solve Regression case problems.',\n",
       "    0.9850302934646606)],\n",
       "  [[[68.0, 491.0], [215.0, 491.0], [215.0, 504.0], [68.0, 504.0]],\n",
       "   (' Machine Learning Techniques', 0.9618057608604431)],\n",
       "  [[[324.0, 491.0], [497.0, 491.0], [497.0, 504.0], [324.0, 504.0]],\n",
       "   ('Teachnook - Python developer', 0.9828904271125793)],\n",
       "  [[[67.0, 504.0], [158.0, 504.0], [158.0, 517.0], [67.0, 517.0]],\n",
       "   (' Computer Vision', 0.9712817668914795)],\n",
       "  [[[327.0, 504.0], [599.0, 504.0], [599.0, 517.0], [327.0, 517.0]],\n",
       "   ('During my first internship I gained knowledge of Python and its',\n",
       "    0.9846272468566895)],\n",
       "  [[[67.0, 514.0], [148.0, 516.0], [148.0, 530.0], [67.0, 528.0]],\n",
       "   (' Deep Learning', 0.9760493040084839)],\n",
       "  [[[328.0, 517.0], [616.0, 518.0], [616.0, 529.0], [328.0, 528.0]],\n",
       "   ('dominance in various domain and came across basics to integrating.',\n",
       "    0.9884191751480103)],\n",
       "  [[[68.0, 529.0], [150.0, 529.0], [150.0, 542.0], [68.0, 542.0]],\n",
       "   ('Web Scrapping', 0.9960237145423889)],\n",
       "  [[[328.0, 530.0], [624.0, 530.0], [624.0, 543.0], [328.0, 543.0]],\n",
       "   ('python with other tools and worked on object oriented programming',\n",
       "    0.9935849905014038)],\n",
       "  [[[72.0, 543.0], [132.0, 543.0], [132.0, 554.0], [72.0, 554.0]],\n",
       "   ('Tensorflow', 0.952351450920105)],\n",
       "  [[[327.0, 554.0], [615.0, 554.0], [615.0, 567.0], [327.0, 567.0]],\n",
       "   ('started to get proficient in functions ,discovering Importantibraries.',\n",
       "    0.9937657117843628)],\n",
       "  [[[62.0, 565.0], [210.0, 565.0], [210.0, 579.0], [62.0, 579.0]],\n",
       "   ('CERTIFICATIONS', 0.967465341091156)],\n",
       "  [[[326.0, 576.0], [415.0, 576.0], [415.0, 590.0], [326.0, 590.0]],\n",
       "   ('PROJECTS', 0.9928267598152161)],\n",
       "  [[[82.0, 596.0], [177.0, 596.0], [177.0, 609.0], [82.0, 609.0]],\n",
       "   (' Python for Everyone', 0.9910932779312134)],\n",
       "  [[[83.0, 610.0], [142.0, 610.0], [142.0, 621.0], [83.0, 621.0]],\n",
       "   ('HTML & CSS', 0.9991105794906616)],\n",
       "  [[[336.0, 601.0], [616.0, 601.0], [616.0, 614.0], [336.0, 614.0]],\n",
       "   ('Age and Gender detection - Uses human face as input image and',\n",
       "    0.9970681667327881)],\n",
       "  [[[83.0, 623.0], [198.0, 623.0], [198.0, 633.0], [83.0, 633.0]],\n",
       "   ('Introduction to Javascript', 0.9995839595794678)],\n",
       "  [[[338.0, 614.0], [623.0, 614.0], [623.0, 624.0], [338.0, 624.0]],\n",
       "   ('predicts the age and gender which uses 3 - CNN and 3 dense layers',\n",
       "    0.9796971082687378)],\n",
       "  [[[82.0, 633.0], [240.0, 635.0], [240.0, 648.0], [82.0, 646.0]],\n",
       "   (' Mathematics for Machine Learning', 0.990888774394989)],\n",
       "  [[[337.0, 626.0], [588.0, 626.0], [588.0, 636.0], [337.0, 636.0]],\n",
       "   ('with 60 epochs of batch size 128,the image size was 128x128',\n",
       "    0.9941872358322144)],\n",
       "  [[[82.0, 647.0], [221.0, 647.0], [221.0, 660.0], [82.0, 660.0]],\n",
       "   (' Machine Learning with Pyhton', 0.9904153943061829)],\n",
       "  [[[336.0, 639.0], [592.0, 638.0], [592.0, 651.0], [336.0, 652.0]],\n",
       "   ('grayscale format The network was able to perform better at',\n",
       "    0.9886683821678162)],\n",
       "  [[[72.0, 659.0], [233.0, 659.0], [233.0, 672.0], [72.0, 672.0]],\n",
       "   (' Python Libraries for Data science', 0.9752159118652344)],\n",
       "  [[[337.0, 652.0], [622.0, 652.0], [622.0, 665.0], [337.0, 665.0]],\n",
       "   ('determining gender but not in age due to small amount of data for',\n",
       "    0.9892297387123108)],\n",
       "  [[[72.0, 671.0], [190.0, 671.0], [190.0, 684.0], [72.0, 684.0]],\n",
       "   ('Flask web development', 0.9998269081115723)],\n",
       "  [[[337.0, 665.0], [409.0, 665.0], [409.0, 676.0], [337.0, 676.0]],\n",
       "   ('each age groups.', 0.9965398907661438)],\n",
       "  [[[82.0, 683.0], [202.0, 683.0], [202.0, 696.0], [82.0, 696.0]],\n",
       "   ('CNN & RNN Architectures', 0.9995914697647095)],\n",
       "  [[[338.0, 676.0], [609.0, 676.0], [609.0, 689.0], [338.0, 689.0]],\n",
       "   (' Phishing URLClassification - Detects whether the url is either',\n",
       "    0.9885309338569641)],\n",
       "  [[[70.0, 695.0], [147.0, 696.0], [147.0, 711.0], [70.0, 709.0]],\n",
       "   (' SQL - MySQL', 0.9093409180641174)],\n",
       "  [[[338.0, 691.0], [620.0, 691.0], [620.0, 701.0], [338.0, 701.0]],\n",
       "   ('safe or unsafe since millions of domains are registered per day and',\n",
       "    0.9858997464179993)],\n",
       "  [[[82.0, 709.0], [167.0, 709.0], [167.0, 722.0], [82.0, 722.0]],\n",
       "   ('NLP for Beginners', 0.9997214078903198)],\n",
       "  [[[338.0, 703.0], [624.0, 703.0], [624.0, 713.0], [338.0, 713.0]],\n",
       "   ('need for security is required by using random forest algorithm with',\n",
       "    0.9876647591590881)],\n",
       "  [[[338.0, 716.0], [603.0, 716.0], [603.0, 727.0], [338.0, 727.0]],\n",
       "   ('the accuracy of 89%.The main issue faced is to preprocess the.',\n",
       "    0.9930493235588074)],\n",
       "  [[[58.0, 735.0], [136.0, 735.0], [136.0, 752.0], [58.0, 752.0]],\n",
       "   ('HONORS', 0.9973052144050598)],\n",
       "  [[[337.0, 729.0], [575.0, 729.0], [575.0, 742.0], [337.0, 742.0]],\n",
       "   ('data by breaking the url based on constrains like google',\n",
       "    0.9932914972305298)],\n",
       "  [[[337.0, 738.0], [433.0, 741.0], [432.0, 754.0], [337.0, 752.0]],\n",
       "   ('indexed,protocols,etc.', 0.9754070043563843)],\n",
       "  [[[71.0, 760.0], [250.0, 760.0], [250.0, 773.0], [71.0, 773.0]],\n",
       "   ('Winner at Hackforworld conducted by', 0.9997822642326355)],\n",
       "  [[[336.0, 753.0], [589.0, 753.0], [589.0, 766.0], [336.0, 766.0]],\n",
       "   ('Face Emotion detection - Classifies the emotions of face in',\n",
       "    0.9986895322799683)],\n",
       "  [[[77.0, 773.0], [211.0, 773.0], [211.0, 786.0], [77.0, 786.0]],\n",
       "   ('Central University of Haryana', 0.9978393316268921)],\n",
       "  [[[337.0, 766.0], [613.0, 766.0], [613.0, 779.0], [337.0, 779.0]],\n",
       "   ('realtime(CV) by initially detecting the face and applying the CNN',\n",
       "    0.9841506481170654)],\n",
       "  [[[67.0, 785.0], [211.0, 785.0], [211.0, 798.0], [67.0, 798.0]],\n",
       "   ('Ulpath Hakathon - First place', 0.9900354146957397)],\n",
       "  [[[337.0, 777.0], [594.0, 778.0], [594.0, 791.0], [337.0, 790.0]],\n",
       "   ('model.The dataset contains 28k training images with 4-CNN',\n",
       "    0.9923693537712097)],\n",
       "  [[[70.0, 798.0], [204.0, 798.0], [204.0, 811.0], [70.0, 811.0]],\n",
       "   ('Participation of CyberHavoc', 0.9862794280052185)],\n",
       "  [[[336.0, 790.0], [615.0, 791.0], [615.0, 804.0], [336.0, 803.0]],\n",
       "   ('layers,3 dense layers of 80 epochs with accuracy of 79% accuracy',\n",
       "    0.993797779083252)],\n",
       "  [[[77.0, 812.0], [228.0, 812.0], [228.0, 822.0], [77.0, 822.0]],\n",
       "   ('Spoken tutorial Python Exam -IIT', 0.9865198731422424)],\n",
       "  [[[337.0, 803.0], [606.0, 804.0], [606.0, 817.0], [337.0, 816.0]],\n",
       "   ('Autism Prediction - Collected data from different sources and',\n",
       "    0.9903263449668884)],\n",
       "  [[[78.0, 824.0], [142.0, 824.0], [142.0, 834.0], [78.0, 834.0]],\n",
       "   ('Bomaby -80%', 0.9827066659927368)],\n",
       "  [[[337.0, 816.0], [622.0, 816.0], [622.0, 829.0], [337.0, 829.0]],\n",
       "   ('analyzed the key factors of the mental disorder as features to build',\n",
       "    0.9903185367584229)],\n",
       "  [[[337.0, 829.0], [621.0, 829.0], [621.0, 842.0], [337.0, 842.0]],\n",
       "   ('an ML. model that classifies positive or negative with calculation of',\n",
       "    0.9844096302986145)],\n",
       "  [[[336.0, 842.0], [395.0, 843.0], [395.0, 854.0], [336.0, 853.0]],\n",
       "   ('autism score.', 0.9995552897453308)]]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rex = \"\"\n",
    "for idx in range(len(result)):\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        rex+=\"\".join(line[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"+91 8438541785HARISUDHAN.Sgithub.com/Harisudhan5STUDENTspeaktoharisudhan@gmail.comhari-sudhan-20373a224inSUMMARYHighly motivated Data science graduate with strong foundation in Python to work with data related projects andgained some practical experience in internships.Passionate about learning skills and working with real - worldproblems. Proficient in libraries required for data handling ,preprocessing, analysis and basic concepts of neuralnetworks, in deep learning,image processing by undergoing handson - projects to demonstrate my knowledge.EDUCATIONPROFESSIONAL EXPERIENCESt.Joseph's College of EngineeringNiograph - InternBachelor's Degree in Artificial IntelligenceAs a Data science intern I worked on company customer-.and Data Science. CGPA - 8.9relationship-management project which involves scrapping data2021 - 2025from website, storing in database, building machine learning modelto predict the target customers and vizualizing dashboards toA.R.L.M .Matric .Hr.Sec.Schoolunderstand the insights from the data..HSE & SSLCCode Clause - Project Intern2020  2022 As a project intern I came through various machine learningSKILLS algorithms and assigned to work on specific set of projects toanalyze the data and construct models for the use - case. FirstPythonproject was to analyze the flight dataset and to predict the flight SQLdelay time and the second project was to create a model whichFrontend Developmenttakes image as input and gives gender and age as output.Data AnalysisThe Sparks Foundation -Data Science InternImage Processing Being Data Science intern ,I worked with Machine Learning ProjectsFlask Frameworkand Regression problem and solve Regression case problems. Machine Learning TechniquesTeachnook - Python developer Computer VisionDuring my first internship I gained knowledge of Python and its Deep Learningdominance in various domain and came across basics to integrating.Web Scrappingpython with other tools and worked on object oriented programmingTensorflowstarted to get proficient in functions ,discovering Importantibraries.CERTIFICATIONSPROJECTS Python for EveryoneHTML & CSSAge and Gender detection - Uses human face as input image andIntroduction to Javascriptpredicts the age and gender which uses 3 - CNN and 3 dense layers Mathematics for Machine Learningwith 60 epochs of batch size 128,the image size was 128x128 Machine Learning with Pyhtongrayscale format The network was able to perform better at Python Libraries for Data sciencedetermining gender but not in age due to small amount of data forFlask web developmenteach age groups.CNN & RNN Architectures Phishing URLClassification - Detects whether the url is either SQL - MySQLsafe or unsafe since millions of domains are registered per day andNLP for Beginnersneed for security is required by using random forest algorithm withthe accuracy of 89%.The main issue faced is to preprocess the.HONORSdata by breaking the url based on constrains like googleindexed,protocols,etc.Winner at Hackforworld conducted byFace Emotion detection - Classifies the emotions of face inCentral University of Haryanarealtime(CV) by initially detecting the face and applying the CNNUlpath Hakathon - First placemodel.The dataset contains 28k training images with 4-CNNParticipation of CyberHavoclayers,3 dense layers of 80 epochs with accuracy of 79% accuracySpoken tutorial Python Exam -IITAutism Prediction - Collected data from different sources andBomaby -80%analyzed the key factors of the mental disorder as features to buildan ML. model that classifies positive or negative with calculation ofautism score.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
